<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.6.0" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.6.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.6.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.6.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.6.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '6.6.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="心比较乱，工作上也有很多东西要做，比较烦，领导之前说那个事情还没什么思路，先做个爬虫试试吧，打发无聊时光这里看到了yield关键字,python的东西还是不熟,百度了一下大概有个概念,慢慢研究,先放个链接mark一下">
<meta name="keywords" content="python,spider,Scrapy">
<meta property="og:type" content="article">
<meta property="og:title" content="Scrapy入门">
<meta property="og:url" content="https://liudongmeng.github.io/2017/04/08/Scrapy入门/index.html">
<meta property="og:site_name" content="沙扬娜拉呵呵">
<meta property="og:description" content="心比较乱，工作上也有很多东西要做，比较烦，领导之前说那个事情还没什么思路，先做个爬虫试试吧，打发无聊时光这里看到了yield关键字,python的东西还是不熟,百度了一下大概有个概念,慢慢研究,先放个链接mark一下">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://liudongmeng.github.io/2017/04/08/Scrapy入门/scrapy_architecture_02.png">
<meta property="og:updated_time" content="2018-09-08T09:20:09.767Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Scrapy入门">
<meta name="twitter:description" content="心比较乱，工作上也有很多东西要做，比较烦，领导之前说那个事情还没什么思路，先做个爬虫试试吧，打发无聊时光这里看到了yield关键字,python的东西还是不熟,百度了一下大概有个概念,慢慢研究,先放个链接mark一下">
<meta name="twitter:image" content="https://liudongmeng.github.io/2017/04/08/Scrapy入门/scrapy_architecture_02.png">



  <link rel="alternate" href="/atom.xml" title="沙扬娜拉呵呵" type="application/atom+xml" />




  <link rel="canonical" href="https://liudongmeng.github.io/2017/04/08/Scrapy入门/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Scrapy入门 | 沙扬娜拉呵呵</title>
  











  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">沙扬娜拉呵呵</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">Sayonara</p>
      
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br />首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br />标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br />分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br />归档</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-commonweal">

    
    
    
      
    

    

    <a href="/404/" rel="section"><i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br />公益404</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://liudongmeng.github.io/2017/04/08/Scrapy入门/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="博主">
      <meta itemprop="description" content="心情不好，持续走低，且行切低迷……">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="沙扬娜拉呵呵">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Scrapy入门
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建于：2017-04-08 10:39:38" itemprop="dateCreated datePublished" datetime="2017-04-08T10:39:38+08:00">2017-04-08</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="更新于：2018-09-08 17:20:09" itemprop="dateModified" datetime="2018-09-08T17:20:09+08:00">2018-09-08</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/笔记/" itemprop="url" rel="index"><span itemprop="name">笔记</span></a></span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/笔记/Scrapy/" itemprop="url" rel="index"><span itemprop="name">Scrapy</span></a></span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/04/08/Scrapy入门/#comments" itemprop="discussionUrl">
                
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/04/08/Scrapy入门/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2017/04/08/Scrapy入门/" class="leancloud_visitors" data-flag-title="Scrapy入门">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Views：</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>心比较乱，工作上也有很多东西要做，比较烦，领导之前说那个事情还没什么思路，先做个爬虫试试吧，打发无聊时光<br>这里看到了yield关键字,python的东西还是不熟,百度了一下大概有个概念,慢慢研究,先放个<a href="http://www.jianshu.com/p/d09778f4e055" title="彻底理解Python中的yield" target="_blank" rel="noopener">链接</a>mark一下</p>
<a id="more"></a>
<h1 id="最简单的爬网页"><a href="#最简单的爬网页" class="headerlink" title="最简单的爬网页"></a>最简单的爬网页</h1><p>先贴一段代码，简单的没什么好讲</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python2.7</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHtml</span><span class="params">(url)</span>:</span></span><br><span class="line">    page = urllib2.urlopen(url)</span><br><span class="line">    html=page.read()</span><br><span class="line">    <span class="keyword">return</span> html</span><br><span class="line">url=<span class="string">"https://liudongmeng.github.io"</span></span><br><span class="line">html=getHtml(url)</span><br><span class="line">print(html)</span><br></pre></td></tr></table></figure>
<h1 id="Scrapy"><a href="#Scrapy" class="headerlink" title="Scrapy"></a>Scrapy</h1><p>百度了一下接下来应该怎么做，无非先拉数据，然后使用正则或者其他手段把目标数据提取出来，之后要能自动翻页之类的，能够持续拉<br>说起来简单，获取网页内容只需要第一步那几行代码，然后就要仔细琢磨一下怎么做了，百度的结果是用<a href="https://scrapy.org/" title="Scrapy官网" target="_blank" rel="noopener">Scrapy</a>这个框架的比较多，先简单学习一下吧<br><img src="scrapy_architecture_02.png" alt="input"><br>看完文档又踩了好多坑……现在开始补充<br>顺着文档看下来，<code>pip install</code>按说应该很简单啊，可是OSX下面安装就是出了一堆问题，比如系统权限了，还有一个什么系统保护机制了，不能在usr和etc这种目录下装东西……看了一圈，一种解决办法是配置pip安装路径，装在当前用户的目录下，要改一堆配置文件<br>最后决定要采用的是<a href="https://virtualenv.pypa.io" title="visualenv官网" target="_blank" rel="noopener">virtualenv</a>，因为不用这么麻烦……<br>写在一起太乱了，放个链接<a href="/2017/04/08/python开发环境的一些配置/" title="python开发环境的一些配置">python开发环境的一些配置</a></p>
<h2 id="Scrapy安装"><a href="#Scrapy安装" class="headerlink" title="Scrapy安装"></a>Scrapy安装</h2><p>搞定了虚拟环境，就可以开始安装配置Scrapy了</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建虚拟环境目录(?暂时这样叫吧)</span></span><br><span class="line">$ visualenv ENV</span><br><span class="line"><span class="comment"># 切换至虚拟环境</span></span><br><span class="line">$ <span class="built_in">source</span> ENV/bin/activate</span><br><span class="line"><span class="comment"># 退出虚拟环境</span></span><br><span class="line">$ deactivate</span><br><span class="line"><span class="comment"># pip安装</span></span><br><span class="line">$ pip install Scrapy</span><br><span class="line"><span class="comment"># 创建名为tutorial的scrapy项目</span></span><br><span class="line">$ scrapy startproject tutorial</span><br></pre></td></tr></table></figure>
<h2 id="Scrapy-Tuurtorial"><a href="#Scrapy-Tuurtorial" class="headerlink" title="Scrapy Tuurtorial"></a>Scrapy Tuurtorial</h2><p>下面是<a href="https://docs.scrapy.org/en/latest/intro/tutorial.html" title="Scrapy官网Tutorial" target="_blank" rel="noopener">Scrapy官网Tutorial</a>给出的教程中的代码</p>
<h3 id="抓取网页"><a href="#抓取网页" class="headerlink" title="抓取网页"></a>抓取网页</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"quotes"</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">        urls = [</span><br><span class="line">            <span class="string">'http://quotes.toscrape.com/page/1/'</span>,</span><br><span class="line">            <span class="string">'http://quotes.toscrape.com/page/2/'</span>,</span><br><span class="line">        ]</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=url, callback=self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        page = response.url.split(<span class="string">"/"</span>)[<span class="number">-2</span>]</span><br><span class="line">        filename = <span class="string">'quotes-%s.html'</span> % page</span><br><span class="line">        <span class="keyword">with</span> open(filename, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(response.body)</span><br><span class="line">        self.log(<span class="string">'Saved file %s'</span> % filename)</span><br></pre></td></tr></table></figure>
<p>之后在tutorial目录下执行命令</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy crawl quotes</span><br><span class="line"><span class="comment"># This command runs the spider with name quotes that we’ve just added, that will send some requests for the quotes.toscrape.com domain. You will get an output similar to this:</span></span><br><span class="line">... (omitted <span class="keyword">for</span> brevity)</span><br><span class="line">2016-12-16 21:24:05 [scrapy.core.engine] INFO: Spider opened</span><br><span class="line">2016-12-16 21:24:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)</span><br><span class="line">2016-12-16 21:24:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023</span><br><span class="line">2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (404) &lt;GET http://quotes.toscrape.com/robots.txt&gt; (referer: None)</span><br><span class="line">2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET http://quotes.toscrape.com/page/1/&gt; (referer: None)</span><br><span class="line">2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET http://quotes.toscrape.com/page/2/&gt; (referer: None)</span><br><span class="line">2016-12-16 21:24:05 [quotes] DEBUG: Saved file quotes-1.html</span><br><span class="line">2016-12-16 21:24:05 [quotes] DEBUG: Saved file quotes-2.html</span><br><span class="line">2016-12-16 21:24:05 [scrapy.core.engine] INFO: Closing spider (finished)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Scrapy schedules the scrapy.Request objects returned by the start_requests method of the Spider. Upon receiving a response for each one, it instantiates Response objects and calls the callback method associated with the request (in this case, the parse method) passing the response as argument.</p>
</blockquote>
<p>这时候ENV目录下保存了两个html文件<code>quotes-1.html</code>,<code>quotes-2.html</code>,这就是爬下来的东西了</p>
<p>接下来是一个简化的实现</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"quotes_shortcut"</span></span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">'http://quotes.toscrape.com/page/1/'</span>,</span><br><span class="line">        <span class="string">'http://quotes.toscrape.com/page/2/'</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self,response)</span>:</span></span><br><span class="line">        page = response.url.split(<span class="string">"/"</span>)[<span class="number">-2</span>]</span><br><span class="line">        finename = <span class="string">'quotes_shortcut-%s.html'</span> % page</span><br><span class="line">        <span class="keyword">with</span> open(finename,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(response.body)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>The parse() method will be called to handle each of the requests for those URLs, even though we haven’t explicitly told Scrapy to do so. This happens because parse() is Scrapy’s default callback method, which is called for requests without an explicitly assigned callback.</p>
</blockquote>
<p>看了一下,这一段大概是为了说明parse是scrapy的默认回调函数,不需要下面这一段代码指定也会被默认调用</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">    <span class="keyword">yield</span> scrapy.Request(url=url, callback=self.parse)</span><br></pre></td></tr></table></figure>
<h3 id="CSSSelector提取数据"><a href="#CSSSelector提取数据" class="headerlink" title="CSSSelector提取数据"></a>CSSSelector提取数据</h3><p>然后是讲scrapy如何提取数据的</p>
<h4 id="extract-method"><a href="#extract-method" class="headerlink" title=".extract() method"></a>.extract() method</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># scrapy shell</span></span><br><span class="line">$ scrapy shell <span class="string">'http://quotes.toscrape.com/page/1/'</span></span><br><span class="line"><span class="comment"># 执行完毕之后看到如下输出</span></span><br><span class="line">[ ... Scrapy <span class="built_in">log</span> here ... ]</span><br><span class="line">2016-09-19 12:09:27 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET http://quotes.toscrape.com/page/1/&gt; (referer: None)</span><br><span class="line">[s] Available Scrapy objects:</span><br><span class="line">[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)</span><br><span class="line">[s]   crawler    &lt;scrapy.crawler.Crawler object at 0x7fa91d888c90&gt;</span><br><span class="line">[s]   item       &#123;&#125;</span><br><span class="line">[s]   request    &lt;GET http://quotes.toscrape.com/page/1/&gt;</span><br><span class="line">[s]   response   &lt;200 http://quotes.toscrape.com/page/1/&gt;</span><br><span class="line">[s]   settings   &lt;scrapy.settings.Settings object at 0x7fa91d888c10&gt;</span><br><span class="line">[s]   spider     &lt;DefaultSpider <span class="string">'default'</span> at 0x7fa91c8af990&gt;</span><br><span class="line">[s] Useful shortcuts:</span><br><span class="line">[s]   shelp()           Shell <span class="built_in">help</span> (<span class="built_in">print</span> this <span class="built_in">help</span>)</span><br><span class="line">[s]   fetch(req_or_url) Fetch request (or URL) and update <span class="built_in">local</span> objects</span><br><span class="line">[s]   view(response)    View response <span class="keyword">in</span> a browser</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="comment"># 接下来可以在scrapy shell中进行一些命令操作</span></span><br><span class="line"><span class="comment"># css selector</span></span><br><span class="line">&gt;&gt;&gt; response.css(<span class="string">'tittle'</span>)</span><br><span class="line">[&lt;Selector xpath=u<span class="string">'descendant-or-self::title'</span> data=u<span class="string">'&lt;title&gt;Quotes to Scrape&lt;/title&gt;'</span>&gt;]</span><br><span class="line">&gt;&gt;&gt; response.css(<span class="string">'tittle::text'</span>)</span><br><span class="line">[&lt;Selector xpath=u<span class="string">'descendant-or-self::title/text()'</span> data=u<span class="string">'Quotes to Scrape'</span>&gt;]</span><br><span class="line">&gt;&gt;&gt; response.css(<span class="string">'title::text'</span>).extract()</span><br><span class="line">[u<span class="string">'Quotes to Scrape'</span>]</span><br><span class="line">&gt;&gt;&gt; response.css(<span class="string">'title'</span>).extract()</span><br><span class="line">[u<span class="string">'&lt;title&gt;Quotes to Scrape&lt;/title&gt;'</span>]</span><br><span class="line"><span class="comment"># extract()方法处理的是一个selectorList实例,如果只想要第一个结果可以如下操作</span></span><br><span class="line">&gt;&gt;&gt; response.css(<span class="string">'title::text'</span>).extract_first()</span><br><span class="line">u<span class="string">'Quotes to Scrape'</span></span><br><span class="line"><span class="comment"># 也可以像数组一样写</span></span><br><span class="line"><span class="comment"># 使用.extract_first()方法在数组长度为0(没有找到对应选择器的元素)的时候可以返回None而不是引发索引错误</span></span><br><span class="line"><span class="comment"># However, using .extract_first() avoids an IndexError and returns None when it doesn’t find any element matching the selection.</span></span><br><span class="line">&gt;&gt;&gt; response.css(<span class="string">'title::text'</span>)[0].extract()</span><br><span class="line">u<span class="string">'Quotes to Scrape'</span></span><br></pre></td></tr></table></figure>
<h4 id="regular-expressions"><a href="#regular-expressions" class="headerlink" title="regular expressions"></a>regular expressions</h4><blockquote>
<p>Besides the extract() and extract_first() methods, you can also use the re() method to extract using regular expressions:</p>
</blockquote>
<p>正则表达式提取数据</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.css(<span class="string">'title::text'</span>).re(r<span class="string">'Quotes.*'</span>)</span><br><span class="line">[u<span class="string">'Quotes to Scrape'</span>]</span><br><span class="line">&gt;&gt;&gt; response.css(<span class="string">'title::text'</span>).re(r<span class="string">'Q\w+'</span>)</span><br><span class="line">[u<span class="string">'Quotes'</span>]</span><br><span class="line">&gt;&gt;&gt; response.css(<span class="string">'title::text'</span>).re(r<span class="string">'(\w+) to (\w+)'</span>)</span><br><span class="line">[u<span class="string">'Quotes'</span>, <span class="string">'Scrape'</span>]</span><br></pre></td></tr></table></figure>
<p>为了验证提取到的数据是否正确,可以调用<code>view(response)</code>方法打开浏览器,在开发者工具中查看页面元素</p>
<h3 id="XPath提取数据"><a href="#XPath提取数据" class="headerlink" title="XPath提取数据"></a>XPath提取数据</h3><p>这一块之前在做selenium的端对端测试的时候有一点点了解,可以用的时候再百度</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.xpath(<span class="string">'//title'</span>)</span><br><span class="line">[&lt;Selector xpath=<span class="string">'//title'</span> data=u<span class="string">'&lt;title&gt;Quotes to Scrape&lt;/title&gt;'</span>&gt;]</span><br><span class="line">&gt;&gt;&gt; response.xpath(<span class="string">'//title/text()'</span>).extract_first()</span><br><span class="line">u<span class="string">'Quotes to Scrape'</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>XPath expressions are very powerful, and are the foundation of Scrapy Selectors. In fact, CSS selectors are converted to XPath under-the-hood. You can see that if you read closely the text representation of the selector objects in the shell.</p>
</blockquote>
<p>这里说XPath是CSSSelector的基础,意思是更强大了</p>
<h3 id="这里讲如何提取最终的目标数据"><a href="#这里讲如何提取最终的目标数据" class="headerlink" title="这里讲如何提取最终的目标数据"></a>这里讲如何提取最终的目标数据</h3><p>这篇教程中的目的是从网站中抓取作品和作者数据,我猜是用正则🙄<br>抓到的网站数据格式如下</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"quote"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"text"</span>&gt;</span>“The world as we have created it is a process of our</span><br><span class="line">    thinking. It cannot be changed without changing our thinking.”<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">span</span>&gt;</span></span><br><span class="line">        by <span class="tag">&lt;<span class="name">small</span> <span class="attr">class</span>=<span class="string">"author"</span>&gt;</span>Albert Einstein<span class="tag">&lt;/<span class="name">small</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"/author/Albert-Einstein"</span>&gt;</span>(about)<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"tags"</span>&gt;</span></span><br><span class="line">        Tags:</span><br><span class="line">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">"tag"</span> <span class="attr">href</span>=<span class="string">"/tag/change/page/1/"</span>&gt;</span>change<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">"tag"</span> <span class="attr">href</span>=<span class="string">"/tag/deep-thoughts/page/1/"</span>&gt;</span>deep-thoughts<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">"tag"</span> <span class="attr">href</span>=<span class="string">"/tag/thinking/page/1/"</span>&gt;</span>thinking<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">"tag"</span> <span class="attr">href</span>=<span class="string">"/tag/world/page/1/"</span>&gt;</span>world<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>这里重新打开scrapy shell</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy shell <span class="string">'http://quotes.toscrape.com'</span></span><br><span class="line"><span class="comment"># 使用CSSSelector获取到了所有的div.quote元素对象</span></span><br><span class="line">&gt;&gt;&gt; response.css(<span class="string">"div.quote"</span>)</span><br><span class="line"><span class="comment"># quote现在就是第一个元素对象</span></span><br><span class="line">&gt;&gt;&gt; quote=response.css(<span class="string">"div.quote"</span>)[0]</span><br><span class="line">&gt;&gt;&gt; quote</span><br><span class="line">&lt;Selector xpath=u<span class="string">"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]"</span> data=u<span class="string">'&lt;div class="quote" itemscope itemtype="h'</span>&gt;</span><br><span class="line"><span class="comment"># 然后根据quote的元素去查找下面的元素</span></span><br><span class="line">&gt;&gt;&gt; title = quote.css(<span class="string">"span.text::text"</span>).extract_first()</span><br><span class="line">&gt;&gt;&gt; title</span><br><span class="line">u<span class="string">'\u201cThe world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.\u201d'</span></span><br><span class="line">&gt;&gt;&gt; author = quote.css(<span class="string">"small.author::text"</span>).extract_first()</span><br><span class="line">&gt;&gt;&gt; author</span><br><span class="line"><span class="string">'Albert Einstein'</span></span><br><span class="line">&gt;&gt;&gt; tags = quote.css(<span class="string">"div.tags a.tag::text"</span>).extract()</span><br><span class="line">&gt;&gt;&gt; tags</span><br><span class="line">[u<span class="string">'change'</span>, u<span class="string">'deep-thoughts'</span>, u<span class="string">'thinking'</span>, u<span class="string">'world'</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; <span class="keyword">for</span> quote <span class="keyword">in</span> response.css(<span class="string">"div.quote"</span>):</span><br><span class="line">...     text=quote.css(<span class="string">"span.text::text"</span>).extract_first()</span><br><span class="line">...     author=quote.css(<span class="string">"small.author::text"</span>).extract_first()</span><br><span class="line">...     tags=quote.css(<span class="string">"div.tags a.tag::text"</span>).extract()</span><br><span class="line">...     <span class="built_in">print</span>(dict(text=text,author=author,tags=tags))</span><br><span class="line">...</span><br><span class="line">&#123;<span class="string">'text'</span>: u<span class="string">'\u201cThe world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.\u201d'</span>, <span class="string">'tags'</span>: [u<span class="string">'change'</span>, u<span class="string">'deep-thoughts'</span>, u<span class="string">'thinking'</span>, u<span class="string">'world'</span>], <span class="string">'author'</span>: u<span class="string">'Albert Einstein'</span>&#125;</span><br><span class="line">&#123;<span class="string">'text'</span>: u<span class="string">'\u201cIt is our choices, Harry, that show what we truly are, far more than our abilities.\u201d'</span>, <span class="string">'tags'</span>: [u<span class="string">'abilities'</span>, u<span class="string">'choices'</span>], <span class="string">'author'</span>: u<span class="string">'J.K. Rowling'</span>&#125;</span><br><span class="line">... a few more of these, omitted <span class="keyword">for</span> brevity</span><br></pre></td></tr></table></figure>
<h3 id="在Spider中提取数据"><a href="#在Spider中提取数据" class="headerlink" title="在Spider中提取数据"></a>在Spider中提取数据</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"quotes_extract"</span></span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">'http://quotes.toscrape.com/page/1/'</span>,</span><br><span class="line">        <span class="string">'http://quotes.toscrape.com/page/2/'</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> quote <span class="keyword">in</span> response.css(<span class="string">'div.quote'</span>):</span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">'text'</span>: quote.css(<span class="string">'span.text::text'</span>).extract_first(),</span><br><span class="line">                <span class="string">'author'</span>: quote.css(<span class="string">'small.author::text'</span>).extract_first(),</span><br><span class="line">                <span class="string">'tags'</span>: quote.css(<span class="string">'div.tags a.tag::text'</span>).extract(),</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure>
<p>运行程序看输出,大概就是下面这样</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy crawl quotes_extract</span><br><span class="line">...</span><br><span class="line">2017-04-08 22:00:06 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 http://quotes.toscrape.com/page/1/&gt;</span><br><span class="line">&#123;<span class="string">'text'</span>: u<span class="string">'\u201cThe world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.\u201d'</span>, <span class="string">'tags'</span>: [u<span class="string">'change'</span>, u<span class="string">'deep-thoughts'</span>, u<span class="string">'thinking'</span>, u<span class="string">'world'</span>], <span class="string">'author'</span>: u<span class="string">'Albert Einstein'</span>&#125;</span><br><span class="line">2017-04-08 22:00:06 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 http://quotes.toscrape.com/page/1/&gt;</span><br><span class="line">&#123;<span class="string">'text'</span>: u<span class="string">'\u201cIt is our choices, Harry, that show what we truly are, far more than our abilities.\u201d'</span>, <span class="string">'tags'</span>: [u<span class="string">'abilities'</span>, u<span class="string">'choices'</span>], <span class="string">'author'</span>: u<span class="string">'J.K. Rowling'</span>&#125;</span><br><span class="line">...</span><br><span class="line"><span class="comment"># 输出json文件</span></span><br><span class="line">$ scrapy crawl quotes_extract -o quotes_extract.json</span><br><span class="line"><span class="comment"># 输出jl文件</span></span><br><span class="line">$ scrapy crawl quotes_extract -o quotes_extract.jl</span><br></pre></td></tr></table></figure>
<blockquote>
<p>The JSON Lines format is useful because it’s stream-like, you can easily append new records to it. It doesn’t have the same problem of JSON when you run twice. Also, as each record is a separate line, you can process big files without having to fit everything in memory, there are tools like JQ to help doing that at the command-line.</p>
</blockquote>
<p>这里终端和上面的输出是一样的,只是把数据保存在了json文件里,随便列几条看看效果就行了</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">&#123;<span class="attr">"text"</span>: <span class="string">"\u201cThe world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.\u201d"</span>, <span class="attr">"author"</span>: <span class="string">"Albert Einstein"</span>, <span class="attr">"tags"</span>: [<span class="string">"change"</span>, <span class="string">"deep-thoughts"</span>, <span class="string">"thinking"</span>, <span class="string">"world"</span>]&#125;,</span><br><span class="line">&#123;<span class="attr">"text"</span>: <span class="string">"\u201cIt is our choices, Harry, that show what we truly are, far more than our abilities.\u201d"</span>, <span class="attr">"author"</span>: <span class="string">"J.K. Rowling"</span>, <span class="attr">"tags"</span>: [<span class="string">"abilities"</span>, <span class="string">"choices"</span>]&#125;,</span><br><span class="line">&#123;<span class="attr">"text"</span>: <span class="string">"\u201cThere are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.\u201d"</span>, <span class="attr">"author"</span>: <span class="string">"Albert Einstein"</span>, <span class="attr">"tags"</span>: [<span class="string">"inspirational"</span>, <span class="string">"life"</span>, <span class="string">"live"</span>, <span class="string">"miracle"</span>, <span class="string">"miracles"</span>]&#125;,</span><br><span class="line">&#123;<span class="attr">"text"</span>: <span class="string">"\u201cThe person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.\u201d"</span>, <span class="attr">"author"</span>: <span class="string">"Jane Austen"</span>, <span class="attr">"tags"</span>: [<span class="string">"aliteracy"</span>, <span class="string">"books"</span>, <span class="string">"classic"</span>, <span class="string">"humor"</span>]&#125;,</span><br><span class="line">&#123;<span class="attr">"text"</span>: <span class="string">"\u201cImperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.\u201d"</span>, <span class="attr">"author"</span>: <span class="string">"Marilyn Monroe"</span>, <span class="attr">"tags"</span>: [<span class="string">"be-yourself"</span>, <span class="string">"inspirational"</span>]&#125;,</span><br><span class="line">&#123;<span class="attr">"text"</span>: <span class="string">"\u201cTry not to become a man of success. Rather become a man of value.\u201d"</span>, <span class="attr">"author"</span>: <span class="string">"Albert Einstein"</span>, <span class="attr">"tags"</span>: [<span class="string">"adulthood"</span>, <span class="string">"success"</span>, <span class="string">"value"</span>]&#125;,</span><br><span class="line">...</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>In small projects (like the one in this tutorial), that should be enough. However, if you want to perform more complex things with the scraped items, you can write an Item Pipeline. A placeholder file for Item Pipelines has been set up for you when the project is created, in tutorial/pipelines.py. Though you don’t need to implement any item pipelines if you just want to store the scraped items.</p>
</blockquote>
<p>这个是管道了,这部分回头再看吧,今天先到这里.么有效率…</p>
<h3 id="如何持续查找所有网页"><a href="#如何持续查找所有网页" class="headerlink" title="如何持续查找所有网页"></a>如何持续查找所有网页</h3><p>这里应该就是找到”下一页”的标记,然后无限向下直到没有下一页为止,也没什么难度,指定选择器而已.<br>下面是quotes网站的下一页元素</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">ul</span> <span class="attr">class</span>=<span class="string">"pager"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"next"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"/page/2/"</span>&gt;</span>Next <span class="tag">&lt;<span class="name">span</span> <span class="attr">aria-hidden</span>=<span class="string">"true"</span>&gt;</span>&amp;rarr;<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>shell里面先看看</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy shell <span class="string">'http://quotes.toscrape.com/'</span></span><br><span class="line">&gt;&gt;&gt; response.css(<span class="string">'li.next a::attr(href)'</span>).extract_first()</span><br><span class="line">u<span class="string">'/page/2/'</span></span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"quotes_next"</span></span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">'http://quotes.toscrape.com/page/1/'</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> quote <span class="keyword">in</span> response.css(<span class="string">'div.quote'</span>):</span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">'text'</span>: quote.css(<span class="string">'span.text::text'</span>).extract_first(),</span><br><span class="line">                <span class="string">'author'</span>: quote.css(<span class="string">'small.author::text'</span>).extract_first(),</span><br><span class="line">                <span class="string">'tags'</span>: quote.css(<span class="string">'div.tags a.tag::text'</span>).extract(),</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        next_page = response.css(<span class="string">'li.next a::attr(href)'</span>).extract_first()</span><br><span class="line">        <span class="keyword">if</span> next_page <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="comment"># 从相对路径获取页面的绝对路径</span></span><br><span class="line">            <span class="comment"># http://quotes.toscrape.com/page/1/</span></span><br><span class="line">            <span class="comment"># /page/2/</span></span><br><span class="line">            <span class="comment"># 拼起来就是http://quotes.toscrape.com/page/2/这样</span></span><br><span class="line">            next_page = response.urljoin(next_page)</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(next_page, callback=self.parse)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>What you see here is Scrapy’s mechanism of following links: when you yield a Request in a callback method, Scrapy will schedule that request to be sent and register a callback method to be executed when that request finishes.</p>
</blockquote>
<p>scrapy回调parse的时候会触发next_page下面的<code>scrapy.Request(next_page, callback=self.parse)</code>代码,循环直到<code>next_page=None</code></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AuthorSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'quotes_author'</span></span><br><span class="line"></span><br><span class="line">    start_urls = [<span class="string">'http://quotes.toscrape.com/'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="comment"># follow links to author pages</span></span><br><span class="line">        <span class="keyword">for</span> href <span class="keyword">in</span> response.css(<span class="string">'.author + a::attr(href)'</span>).extract():</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(response.urljoin(href),</span><br><span class="line">                                 callback=self.parse_author)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># follow pagination links</span></span><br><span class="line">        next_page = response.css(<span class="string">'li.next a::attr(href)'</span>).extract_first()</span><br><span class="line">        <span class="keyword">if</span> next_page <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            next_page = response.urljoin(next_page)</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(next_page, callback=self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_author</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">extract_with_css</span><span class="params">(query)</span>:</span></span><br><span class="line">            <span class="keyword">return</span> response.css(query).extract_first().strip()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">'name'</span>: extract_with_css(<span class="string">'h3.author-title::text'</span>),</span><br><span class="line">            <span class="string">'birthdate'</span>: extract_with_css(<span class="string">'.author-born-date::text'</span>),</span><br><span class="line">            <span class="string">'bio'</span>: extract_with_css(<span class="string">'.author-description::text'</span>),</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
<p>这一段是先加载页面之后拿到所有的作者的链接,然后在parse中新建scrapy.Request()请求,触发parse_author回调,在作者页面中拿到作者信息<br>我在想这个东西会不会一不小心搞成递归了…</p>
<blockquote>
<p>Another interesting thing this spider demonstrates is that, even if there are many quotes from the same author, we don’t need to worry about visiting the same author page multiple times. By default, Scrapy filters out duplicated requests to URLs already visited, avoiding the problem of hitting servers too much because of a programming mistake. This can be configured by the setting DUPEFILTER_CLASS.</p>
</blockquote>
<p>话说这是自带防止递归的功能?框架果然是好东西,急人之所急啊</p>
<h3 id="传递参数"><a href="#传递参数" class="headerlink" title="传递参数"></a>传递参数</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"quotes_tags"</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">        url = <span class="string">'http://quotes.toscrape.com/'</span></span><br><span class="line">        tag = getattr(self, <span class="string">'tag'</span>, <span class="keyword">None</span>)</span><br><span class="line">        <span class="keyword">if</span> tag <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            url = url + <span class="string">'tag/'</span> + tag</span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(url, self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> quote <span class="keyword">in</span> response.css(<span class="string">'div.quote'</span>):</span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">'text'</span>: quote.css(<span class="string">'span.text::text'</span>).extract_first(),</span><br><span class="line">                <span class="string">'author'</span>: quote.css(<span class="string">'small.author::text'</span>).extract_first(),</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        next_page = response.css(<span class="string">'li.next a::attr(href)'</span>).extract_first()</span><br><span class="line">        <span class="keyword">if</span> next_page <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            next_page = response.urljoin(next_page)</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(next_page, self.parse)</span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl quotes_tags -o quotes_tags.json -a tag=humor</span><br></pre></td></tr></table></figure>
<p>最终获取的结果只有humor类型的</p>
<blockquote>
<p>You can learn more about <a href="https://docs.scrapy.org/en/latest/topics/spiders.html#spiderargs" title="spider-arguments" target="_blank" rel="noopener">handling spider arguments here</a>.</p>
</blockquote>
<p>今天就到这里,消化一下.</p>

      
    </div>

    

    
    
    

    

    
       
    
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/python/" rel="tag"># python</a>
          
            <a href="/tags/spider/" rel="tag"># spider</a>
          
            <a href="/tags/Scrapy/" rel="tag"># Scrapy</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/03/30/2017-03-30/" rel="next" title="2017-03-30">
                <i class="fa fa-chevron-left"></i> 2017-03-30
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/04/08/python开发环境的一些配置/" rel="prev" title="python开发环境的一些配置">
                python开发环境的一些配置 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">博主</p>
              <p class="site-description motion-element" itemprop="description">心情不好，持续走低，且行切低迷……</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">26</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">23</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">19</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://nlpfxb.github.io/" title="https://nlpfxb.github.io/" rel="noopener" target="_blank">冯·有钱人·🐶富贵·波·</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://ammeyjohn.github.io/" title="https://ammeyjohn.github.io/" rel="noopener" target="_blank">Patrick</a>
                  </li>
                
              </ul>
            </div>
          

          
            
          
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#最简单的爬网页"><span class="nav-number">1.</span> <span class="nav-text">最简单的爬网页</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Scrapy"><span class="nav-number">2.</span> <span class="nav-text">Scrapy</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Scrapy安装"><span class="nav-number">2.1.</span> <span class="nav-text">Scrapy安装</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Scrapy-Tuurtorial"><span class="nav-number">2.2.</span> <span class="nav-text">Scrapy Tuurtorial</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#抓取网页"><span class="nav-number">2.2.1.</span> <span class="nav-text">抓取网页</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CSSSelector提取数据"><span class="nav-number">2.2.2.</span> <span class="nav-text">CSSSelector提取数据</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#extract-method"><span class="nav-number">2.2.2.1.</span> <span class="nav-text">.extract() method</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#regular-expressions"><span class="nav-number">2.2.2.2.</span> <span class="nav-text">regular expressions</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#XPath提取数据"><span class="nav-number">2.2.3.</span> <span class="nav-text">XPath提取数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#这里讲如何提取最终的目标数据"><span class="nav-number">2.2.4.</span> <span class="nav-text">这里讲如何提取最终的目标数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#在Spider中提取数据"><span class="nav-number">2.2.5.</span> <span class="nav-text">在Spider中提取数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#如何持续查找所有网页"><span class="nav-number">2.2.6.</span> <span class="nav-text">如何持续查找所有网页</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#传递参数"><span class="nav-number">2.2.7.</span> <span class="nav-text">传递参数</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">博主</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.7.1</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v6.6.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    
	
    

    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.6.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.6.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.6.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.6.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.6.0"></script>



  

  
    <script id="dsq-count-scr" src="https://sayonara-l.disqus.com/count.js" async></script>
  

  
    <script type="text/javascript">
      var disqus_config = function () {
        this.page.url = 'https://liudongmeng.github.io/2017/04/08/Scrapy入门/';
        this.page.identifier = '2017/04/08/Scrapy入门/';
        this.page.title = 'Scrapy入门';
        };
      function loadComments () {
        var d = document, s = d.createElement('script');
        s.src = 'https://sayonara-l.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      }
      
        loadComments();
      
    </script>
  












  





  

  
  <script>
    
    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();

      Counter('get', '/classes/Counter', { where: JSON.stringify({ url }) })
        .done(function ({ results }) {
          if (results.length > 0) {
            var counter = results[0];
            
              var $element = $(document.getElementById(url));
              $element.find('.leancloud-visitors-count').text(counter.time + 1);
            
            Counter('put', `/classes/Counter/${counter.objectId}`, JSON.stringify({ time: { "__op":"Increment", "amount":1 } }))
            
            .fail(function ({ responseJSON }) {
                console.log('Failed to save Visitor num, with error message: ' + responseJSON.error);
            })
          } else {
            
              var $element = $(document.getElementById(url));
              $element.find('.leancloud-visitors-count').text('Counter not initialized! See more at console err msg.');
              console.error('ATTENTION! LeanCloud counter has security bug, see here how to solve it: https://github.com/theme-next/hexo-leancloud-counter-security. \n But you also can use LeanCloud without security, by set \'security\' option to \'false\'.');
            
          }
        })
      .fail(function ({ responseJSON }) {
        console.log('LeanCloud Counter Error:' + responseJSON.code + " " + responseJSON.error);
      });
    }
    

    $(function() {
      $.get('https://app-router.leancloud.cn/2/route?appId=' + "1YIwJodingrc40me9MEjtcVN-gzGzoHsz")
        .done(function ({ api_server }) {
          var Counter = function (method, url, data) {
            return $.ajax({
              method: method,
              url: `https://${api_server}/1.1${url}`,
              headers: {
                'X-LC-Id': "1YIwJodingrc40me9MEjtcVN-gzGzoHsz",
                'X-LC-Key': "3soCSK6DKfVD7oRO7RAkbsfi",
                'Content-Type': 'application/json',
              },
              data: data,
            });
          };
          
          addCount(Counter);
          
        })
    });
  </script>



  

  

  

  

  
  

  

  

  

  

  

  

</body>
</html>
